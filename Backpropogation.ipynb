{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  lpa\n",
       "0     8              8    4\n",
       "1     7              9    5\n",
       "2     6             10    6\n",
       "3     5             12    7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]], columns=['cgpa','profile_score','lpa'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing weights and biases\n",
    "\n",
    "- weights initialized by 0.1\n",
    "- biases initialized by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeParameters(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {} # d[weight] = value\n",
    "    L = len(layer_dims)\n",
    "\n",
    "    for l in range(1,L):\n",
    "        # each neuron in a  layer has weight emerging from it and bias\n",
    "        # if layer_dim = [ 2,2,1 ] then weights in first layer and second layer will be 2*2 = 4 weights\n",
    "        parameters['W'+str(l)] = np.ones((layer_dims[l-1],layer_dims[l]))*0.1\n",
    "        parameters['b'+str(l)] = np.zeros((layer_dims[l],1))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = initializeParameters([2,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to generate output of a neuron\n",
    "\n",
    "requires : \n",
    "- all the inputs to that neurons of that layer\n",
    "- all the weights of those inputs \n",
    "- bias of that neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(Inp,W,b): #input,w,b are input vector, weight matrix and bias vector for a layer\n",
    "    z = np.dot(W.T,Inp)+b\n",
    "    return z  # returning output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, params):\n",
    "    init_input = X\n",
    "    L = len(params) // 2  # because each layer has w and b, params has w and b for all layers\n",
    "\n",
    "    for l in range(1, L + 1):\n",
    "        Inp = init_input\n",
    "        Wl = params['W' + str(l)]\n",
    "        bl = params['b' + str(l)]  # Corrected: Retrieving bias vector 'b' instead of 'W'\n",
    "        Output = linear_forward(Inp, Wl, bl)  # output from layer l is input to layer l+1\n",
    "        init_input = Output  # Update input for the next layer\n",
    "\n",
    "    return Output, Inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(parameters,y,y_hat,A1,X):\n",
    "  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.001 * 2 * (y - y_hat)*A1[0][0])\n",
    "  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat)*A1[1][0])\n",
    "  parameters['b2'][0][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat))\n",
    "\n",
    "  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[0][0])\n",
    "  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[1][0])\n",
    "  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0])\n",
    "\n",
    "  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[0][0])\n",
    "  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[1][0])\n",
    "  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs,df,params):\n",
    "    for i in range(epochs):\n",
    "        Loss = []\n",
    "        #1. pick a random data sample \n",
    "        for j in range(df.shape[0]):\n",
    "            x = df[['cgpa','profile_score']].values[j].reshape(2,1) #(features,rows)\n",
    "            y = df[['lpa']].values[j][0]\n",
    "\n",
    "            #forward prop\n",
    "            y_hat,Inp = forward_propagation(x,params)\n",
    "            update_params(params,y,y_hat,x,Inp)\n",
    "\n",
    "            #append current loss to Loss\n",
    "            Loss.append((y-y_hat)**2)\n",
    "\n",
    "        print(\"Epoch - \",i+1, \"Loss :\",np.array(Loss).mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -  1 Loss : 21.803820123908743\n",
      "Epoch -  2 Loss : 9.71474272919271\n",
      "Epoch -  3 Loss : 3.2685228568621616\n",
      "Epoch -  4 Loss : 1.3372511019530116\n",
      "Epoch -  5 Loss : 1.1166283505177543\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "params = initializeParameters([2,2,1])\n",
    "train(epochs,df,params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
